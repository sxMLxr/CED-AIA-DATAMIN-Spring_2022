{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0ff7c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "#import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3750cfb",
   "metadata": {},
   "source": [
    "## Lets load the data that we preprocessed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76e2aa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"../Accident_Stats/Processed_USAccidents.csv\")\n",
    "df.drop(['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f2c7e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()   #see data and start looking to filter out data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafdaafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460bee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum() # View any null data stats... confirm no further processing is needed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fe7479",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns   #print columns and verify preprocessed data is what we want to use to train models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04b3217",
   "metadata": {},
   "source": [
    "# Severity will be our expected \"result\"\n",
    "## All other columns will be used to train, test the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa4c49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Severity']\n",
    "X = df.drop(['Severity'], axis = 1)\n",
    "print(f\"==X headers: \\n\", X.head(2))\n",
    "print(f\"==Y headers: \\n\", y.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854d9ba2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# Make an instance of the Model\n",
    "pca = PCA(.95)\n",
    "pca.fit(X)\n",
    "train_img = pca.transform(X)\n",
    "train = pd.DataFrame(train_img)\n",
    "train.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a125862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb815be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8584427",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(X_train.head())\n",
    "print(X_test.head())\n",
    "print(y_train.head())\n",
    "print(y_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c1a9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Fit on training set only.\n",
    "scaler.fit(X_train)\n",
    "# Apply transform to both the training set and the test set.\n",
    "transform = scaler.transform(X_train)\n",
    "#test_img = scaler.transform(test_img)\n",
    "scalar_train = pd.DataFrame(transform)\n",
    "scalar_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2d2d02",
   "metadata": {},
   "source": [
    "# We have values... time to set models and test which model will be appropiate for this dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd112635",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "676c73ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6ac0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xdt_train, Xdt_test, ydt_train, ydt_test = train_test_split(X, y, test_size=0.3, random_state=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e922b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "dtscaler = StandardScaler()\n",
    "# Fit on training set only.\n",
    "dtscaler.fit(Xdt_train)\n",
    "# Apply transform to both the training set and the test set.\n",
    "dttransform = dtscaler.transform(Xdt_train)\n",
    "dtscalar_train = pd.DataFrame(dttransform)\n",
    "dtscalar_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13fddc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtscalert = StandardScaler()\n",
    "# Fit on training set only.\n",
    "dtscalert.fit(Xdt_test)\n",
    "# Apply transform to both the training set and the test set.\n",
    "dttransformt = dtscalert.transform(Xdt_test)\n",
    "#test_img = scaler.transform(test_img)\n",
    "dtscalar_test = pd.DataFrame(dttransformt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a5519f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtclf = DecisionTreeClassifier(random_state = 120, criterion=\"entropy\", max_depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebeb50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtclf = dtclf.fit(dtscalar_train, ydt_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c93ed7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dty_pred = dtclf.predict(dtscalar_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87be4832",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DT Accuracy:\",metrics.accuracy_score(ydt_test, dty_pred))  #Accuracy is 0.8914108783591436"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4f5085",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(ydt_test, dty_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6554d32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check Important features\n",
    "feature_importances_df = pd.DataFrame(\n",
    "    {\"feature\": list(X.columns), \"importance\": dtclf.feature_importances_}\n",
    ").sort_values(\"importance\", ascending=False)\n",
    "\n",
    "# Display\n",
    "feature_importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099e5c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a bar plot\n",
    "sns.barplot(x=feature_importances_df.feature, y=feature_importances_df.importance)\n",
    "# Add labels to your\n",
    "\n",
    "plt.xlabel(\"Feature Importance Score\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.title(\"Visualizing Important Features\")\n",
    "plt.xticks(\n",
    "    rotation=45, horizontalalignment=\"right\", fontweight=\"light\", fontsize=\"x-large\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13640f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Temperature(F)','No_Exit', 'Stop','Station','Roundabout','Railway','Crossing','Give_Way',\n",
    "              'Bump','Weather_Condition','Wind_Speed(mph)','Wind_Direction','Turning_Loop'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1efe4fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Severity', 'Wind_Chill(F)', 'Humidity(%)', 'Pressure(in)',\n",
       "       'Visibility(mi)', 'Precipitation(in)', 'Junction', 'Traffic_Signal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2caf4358",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Severity']\n",
    "X = df.drop(['Severity'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f89d30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xdt_train, Xdt_test, ydt_train, ydt_test = train_test_split(X, y, test_size=0.3, random_state=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da98f6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "dtscaler = StandardScaler()\n",
    "# Fit on training set only.\n",
    "dtscaler.fit(Xdt_train)\n",
    "# Apply transform to both the training set and the test set.\n",
    "dttransform = dtscaler.transform(Xdt_train)\n",
    "dtscalar_train = pd.DataFrame(dttransform)\n",
    "dtscalar_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1deadeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtscalert = StandardScaler()\n",
    "# Fit on training set only.\n",
    "dtscalert.fit(Xdt_test)\n",
    "# Apply transform to both the training set and the test set.\n",
    "dttransformt = dtscalert.transform(Xdt_test)\n",
    "#test_img = scaler.transform(test_img)\n",
    "dtscalar_test = pd.DataFrame(dttransformt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50c2f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtclf = DecisionTreeClassifier(random_state = 120, criterion=\"entropy\", max_depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62904f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtclf = dtclf.fit(dtscalar_train, ydt_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca45c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "dty_pred = dtclf.predict(dtscalar_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e458baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DT Accuracy:\",metrics.accuracy_score(ydt_test, dty_pred))  \n",
    "#Accuracy is features Removed = 0.8903846401664474"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0ac270",
   "metadata": {},
   "outputs": [],
   "source": [
    "Decision TREE Conclusion:\n",
    "    # DT Accuracy with Scalar and Features Removed : 0.8903846401664474\n",
    "    # DT Accuracy with Scalar only:                  0.8903846401664474"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870f32ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean out pd.DataFrames we created\n",
    "Xdt_test= None\n",
    "Xdt_train = None\n",
    "dtscalar_test = None\n",
    "dtscalar_train = None\n",
    "del [Xdt_test, Xdt_train,  dtscalar_test, dtscalar_train] \n",
    "\n",
    "%who_ls DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ec04b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean out pd.Series we created\n",
    "ydt_test = None\n",
    "del ydt_test\n",
    "ydt_train = None\n",
    "del ydt_train\n",
    "%who_ls Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e09e25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%who_ls ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0078be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for xt in [dttransform, dttransformt, dty_pred]:\n",
    "    xt = None\n",
    "del dttransform \n",
    "del dttransformt\n",
    "del dty_pred\n",
    "del xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5335bbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%who_ls ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df09be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5914be25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "#fix this... should work with no issue\n",
    "import graphviz\n",
    "export_graphviz(dtclf, out_file=\"mytree_entropy.dot\")\n",
    "with open(\"mytree_entropy.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "graphviz.Source(dot_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e079d68",
   "metadata": {},
   "source": [
    "# Random Forest w/Scaler & Features Removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d00583e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "XRF_train, XRF_test, yRF_train, yRF_test = train_test_split(X, y, test_size=0.3, random_state=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b2af202",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.897134</td>\n",
       "      <td>0.869862</td>\n",
       "      <td>-0.255312</td>\n",
       "      <td>0.326964</td>\n",
       "      <td>-0.083467</td>\n",
       "      <td>-0.337152</td>\n",
       "      <td>-0.320851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.224702</td>\n",
       "      <td>0.648315</td>\n",
       "      <td>0.500556</td>\n",
       "      <td>0.326964</td>\n",
       "      <td>-0.083467</td>\n",
       "      <td>-0.337152</td>\n",
       "      <td>-0.320851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.137376</td>\n",
       "      <td>-0.237874</td>\n",
       "      <td>0.616843</td>\n",
       "      <td>0.326964</td>\n",
       "      <td>-0.083467</td>\n",
       "      <td>-0.337152</td>\n",
       "      <td>-0.320851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.052310</td>\n",
       "      <td>-1.079754</td>\n",
       "      <td>-0.468506</td>\n",
       "      <td>0.326964</td>\n",
       "      <td>-0.083467</td>\n",
       "      <td>-0.337152</td>\n",
       "      <td>3.116707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000122</td>\n",
       "      <td>-0.282184</td>\n",
       "      <td>0.539318</td>\n",
       "      <td>-1.164988</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>-0.337152</td>\n",
       "      <td>-0.320851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6\n",
       "0  0.897134  0.869862 -0.255312  0.326964 -0.083467 -0.337152 -0.320851\n",
       "1  0.224702  0.648315  0.500556  0.326964 -0.083467 -0.337152 -0.320851\n",
       "2 -0.137376 -0.237874  0.616843  0.326964 -0.083467 -0.337152 -0.320851\n",
       "3  1.052310 -1.079754 -0.468506  0.326964 -0.083467 -0.337152  3.116707\n",
       "4  0.000122 -0.282184  0.539318 -1.164988  0.000210 -0.337152 -0.320851"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scalerRF = StandardScaler()\n",
    "# Fit on training set only.\n",
    "scalerRF.fit(XRF_train)\n",
    "# Apply transform to both the training set and the test set.\n",
    "transformRF = scalerRF.transform(XRF_train)\n",
    "scalarRF_train = pd.DataFrame(transformRF)\n",
    "scalarRF_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "535f7fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFscalert = StandardScaler()\n",
    "# Fit on training set only.\n",
    "RFscalert.fit(XRF_test)\n",
    "# Apply transform to both the training set and the test set.\n",
    "RFtransformt = RFscalert.transform(XRF_test)\n",
    "#test_img = scaler.transform(test_img)\n",
    "scalarRF_test = pd.DataFrame(RFtransformt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea413c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc8587f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFclf=RandomForestClassifier(n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac9d9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFclf.fit(scalarRF_train, yRF_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf3d5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(yRF_test, yRF_pred))\n",
    "# prior results == Accuracy Scalar only: 0.8869861047817311\n",
    "# Accuracy Scalar and Features removed:  0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b57630",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy with Features Removed == "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
