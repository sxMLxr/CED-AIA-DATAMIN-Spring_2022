{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop 8: Linear Regression\n",
    "\n",
    "\n",
    "In this exercise, you will apply linear regression and Lasso regression methods to the dataset supplied to you, and then compare their results to determine whether Lasso regression is needed for this dataset:\n",
    "\n",
    "**Dataset description**: You are provided a dataset with 20 variables. Variables $x1\\ -\\ x19$ refer to the independent variables, while variable $y$ is your dependent variable. Training data is stored in the file `/etc/data/regression-train.csv`.\n",
    "\n",
    "**Note**: The TA will use a test set to verify your solution. The format (independent variables $x1\\ -\\ x19$, dependent variable  $y$) will be same, but TA's file may contain different number of data points than the split version from training set. Please ensure you take this into account, and do not hard code any dimensions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-09b96daf1e0cf44e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bb0404ec9da83a2b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x12</th>\n",
       "      <th>x13</th>\n",
       "      <th>x14</th>\n",
       "      <th>x15</th>\n",
       "      <th>x16</th>\n",
       "      <th>x17</th>\n",
       "      <th>x18</th>\n",
       "      <th>x19</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>508</td>\n",
       "      <td>44</td>\n",
       "      <td>60</td>\n",
       "      <td>718</td>\n",
       "      <td>42</td>\n",
       "      <td>234</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>52</td>\n",
       "      <td>8</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>1998</td>\n",
       "      <td>472</td>\n",
       "      <td>136</td>\n",
       "      <td>236</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>610.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1020</td>\n",
       "      <td>106</td>\n",
       "      <td>198</td>\n",
       "      <td>1620</td>\n",
       "      <td>126</td>\n",
       "      <td>680</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>104</td>\n",
       "      <td>36</td>\n",
       "      <td>614</td>\n",
       "      <td>0</td>\n",
       "      <td>5744</td>\n",
       "      <td>1642</td>\n",
       "      <td>294</td>\n",
       "      <td>348</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>2300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1118</td>\n",
       "      <td>146</td>\n",
       "      <td>828</td>\n",
       "      <td>704</td>\n",
       "      <td>32</td>\n",
       "      <td>698</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "      <td>122</td>\n",
       "      <td>18</td>\n",
       "      <td>842</td>\n",
       "      <td>0</td>\n",
       "      <td>6324</td>\n",
       "      <td>1748</td>\n",
       "      <td>282</td>\n",
       "      <td>718</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>1850.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>922</td>\n",
       "      <td>70</td>\n",
       "      <td>452</td>\n",
       "      <td>222</td>\n",
       "      <td>48</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>22</td>\n",
       "      <td>152</td>\n",
       "      <td>2</td>\n",
       "      <td>1360</td>\n",
       "      <td>320</td>\n",
       "      <td>224</td>\n",
       "      <td>98</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>270.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>526</td>\n",
       "      <td>60</td>\n",
       "      <td>294</td>\n",
       "      <td>162</td>\n",
       "      <td>18</td>\n",
       "      <td>164</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>46</td>\n",
       "      <td>8</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>1776</td>\n",
       "      <td>440</td>\n",
       "      <td>140</td>\n",
       "      <td>172</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>630</td>\n",
       "      <td>50</td>\n",
       "      <td>78</td>\n",
       "      <td>996</td>\n",
       "      <td>48</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>120</td>\n",
       "      <td>26</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>1260</td>\n",
       "      <td>302</td>\n",
       "      <td>152</td>\n",
       "      <td>110</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>330</td>\n",
       "      <td>32</td>\n",
       "      <td>38</td>\n",
       "      <td>664</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>392</td>\n",
       "      <td>88</td>\n",
       "      <td>78</td>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>1146</td>\n",
       "      <td>156</td>\n",
       "      <td>262</td>\n",
       "      <td>2628</td>\n",
       "      <td>194</td>\n",
       "      <td>840</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>120</td>\n",
       "      <td>24</td>\n",
       "      <td>940</td>\n",
       "      <td>0</td>\n",
       "      <td>6396</td>\n",
       "      <td>1714</td>\n",
       "      <td>288</td>\n",
       "      <td>664</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>1920.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>472</td>\n",
       "      <td>22</td>\n",
       "      <td>398</td>\n",
       "      <td>250</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>232</td>\n",
       "      <td>2</td>\n",
       "      <td>2230</td>\n",
       "      <td>540</td>\n",
       "      <td>112</td>\n",
       "      <td>114</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>460.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1120</td>\n",
       "      <td>132</td>\n",
       "      <td>18</td>\n",
       "      <td>664</td>\n",
       "      <td>130</td>\n",
       "      <td>520</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>178</td>\n",
       "      <td>192</td>\n",
       "      <td>16</td>\n",
       "      <td>466</td>\n",
       "      <td>2</td>\n",
       "      <td>3578</td>\n",
       "      <td>940</td>\n",
       "      <td>322</td>\n",
       "      <td>310</td>\n",
       "      <td>8</td>\n",
       "      <td>52</td>\n",
       "      <td>1250.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       x1   x2   x3    x4   x5   x6  x7  x8   x9  x10  x11  x12  x13   x14  \\\n",
       "0     508   44   60   718   42  234   0   0   56   52    8  216    0  1998   \n",
       "1    1020  106  198  1620  126  680   2   2  112  104   36  614    0  5744   \n",
       "2    1118  146  828   704   32  698   2   2   96  122   18  842    0  6324   \n",
       "3     922   70  452   222   48  150   0   0  108  108   22  152    2  1360   \n",
       "4     526   60  294   162   18  164   2   2   52   46    8  166    0  1776   \n",
       "..    ...  ...  ...   ...  ...  ...  ..  ..  ...  ...  ...  ...  ...   ...   \n",
       "127   630   50   78   996   48  188   2   2   70  120   26  136    0  1260   \n",
       "128   330   32   38   664    4   20   0   2   26   18    4   36    2   392   \n",
       "129  1146  156  262  2628  194  840   0   0  170  120   24  940    0  6396   \n",
       "130   472   22  398   250    2  128   0   0   54   30   26  232    2  2230   \n",
       "131  1120  132   18   664  130  520   2   2  178  192   16  466    2  3578   \n",
       "\n",
       "      x15  x16  x17  x18  x19       y  \n",
       "0     472  136  236   12    4   610.0  \n",
       "1    1642  294  348   14   20  2300.0  \n",
       "2    1748  282  718   16    4  1850.0  \n",
       "3     320  224   98    4   36   270.0  \n",
       "4     440  140  172    8    2   500.0  \n",
       "..    ...  ...  ...  ...  ...     ...  \n",
       "127   302  152  110    6   26   310.0  \n",
       "128    88   78   36    6    4   150.0  \n",
       "129  1714  288  664   16   18  1920.0  \n",
       "130   540  112  114    8    0   460.0  \n",
       "131   940  322  310    8   52  1250.0  \n",
       "\n",
       "[132 rows x 20 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the data\n",
    "df = pd.read_csv(\"./data/regression-train.csv\")\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-eef1468ef64e4e98",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_unscaled, X_test_unscaled, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For regression, it is particularly important to normalize our data before\n",
    "# training the model, so we can better interpret our coefficients\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_unscaled)\n",
    "X_train = scaler.transform(X_train_unscaled)\n",
    "X_test = scaler.transform(X_test_unscaled)\n",
    "#print(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have given you a function to caculate the RMSE of a regression model, given its predictions and the ground truth y-values of the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2d1c351adc22eb14",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def calculate_rmse(y_true, y_pred):\n",
    "  \n",
    "  # Inputs:\n",
    "  # y_true: ground truth dependent variable values, of type vector\n",
    "  # y_pred: prediction outcomes from any regression method, with the same length as y_true\n",
    "  \n",
    "  # Outputs:\n",
    "  # a single value of type double, with the RMSE value\n",
    "    return(math.sqrt(np.sum((y_true - y_pred)**2)/len(y_true)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Linear Regression (Group)\n",
    "You will write code in the function `alda_regression_linear` to train simple linear regression. Detailed instructions for implementation and allowed packages have been provided the comments.\n",
    "\n",
    "Before your begin, read the documentation on sklearn's [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "alda_regression_linear",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def alda_regression_linear(X_train, X_test, y_train):\n",
    "    # Perform linear regression\n",
    "    # Inputs:\n",
    "    # X_train: training data frame(19 variables, x1-x19)\n",
    "    # X_test: test data frame(19 variables, x1-x19)\n",
    "    # y_train: dependent variable, training data (vector, continous type)\n",
    "\n",
    "    # Output:\n",
    "    # A tuple containing:\n",
    "    # - The regression model and \n",
    "    # - The list of predictions on test data (X_test) (vector) \n",
    "  \n",
    "    # allowed packages: sklearn.linear_model\n",
    "  \n",
    "    # Function hints: Read the documentation for the functions LinearRegression (link above)\n",
    "    regression = LinearRegression()\n",
    "    regression.fit(X_train, y_train)\n",
    "    pred = regression.predict(X_test)\n",
    "    return (regression, pred)\n",
    "    # write code for building a linear regression model using X_train, y_train\n",
    "    #raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE: 524.953283852617\n",
      "Test RMSE: 787.9099436300614\n",
      "\n",
      "Model coefficients:\n",
      "[   48.18082989    65.73979512   210.77335056   122.5616241\n",
      "   124.07603501   290.38608009   123.86744484   -83.03161175\n",
      "   270.17717717   -48.56806094   -23.51778917  -941.63419412\n",
      "   -89.00842661 -4044.98292672  5073.44151699  -544.21209605\n",
      "   137.73175811  -101.04154575   235.26578305]\n"
     ]
    }
   ],
   "source": [
    "# Now test your model\n",
    "lr_model, lr_predictions = alda_regression_linear(X_train, X_test, y_train)\n",
    "\n",
    "print(f'Training RMSE: {calculate_rmse(y_train, lr_model.predict(X_train))}')\n",
    "print(f'Test RMSE: {calculate_rmse(y_test, lr_predictions)}')\n",
    "print('')\n",
    "\n",
    "# Which attributes are most predictive of the outcome variable?\n",
    "print(f'Model coefficients:\\n{lr_model.coef_}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "alda_regression_linear-public",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "lr_model, simple_linear_regression_result = alda_regression_linear(X_train, X_test, y_train)\n",
    "np.testing.assert_equal(simple_linear_regression_result.shape, (27,))\n",
    "np.testing.assert_almost_equal(calculate_rmse(y_test,simple_linear_regression_result),787.9099436300563)\n",
    "np.testing.assert_almost_equal(lr_model.coef_[0], 48.18082989)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "alda_regression_linear-private",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Here's some test cases to make sure you're right\n",
    "df_test = pd.read_csv(\"./data/regression-test.csv\")\n",
    "X_test2 = df_test.iloc[:,:-1]\n",
    "y_test2 = df_test.iloc[:,-1]\n",
    "\n",
    "lr_model, simple_linear_regression_result = alda_regression_linear(X, X_test2, y)\n",
    "np.testing.assert_equal(simple_linear_regression_result.shape, (66,))\n",
    "np.testing.assert_almost_equal(calculate_rmse(y_test2,simple_linear_regression_result),946.4318403560575)\n",
    "# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Lasso Regression (Group)\n",
    "You will write code in the function `alda_regression_lasso` to train simple lasso regression. Detailed instructions for implementation and allowed packages have been provided the comments. \n",
    "\n",
    "Before your begin, read the documentation on sklearn's [LassoCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html) - a Lasso regression model that uses CV to tune its hyperparameters.\n",
    "\n",
    "**Note** that the lasso regression model has *built-in* crossvalidation, which it performs on the training dataset provided, to select the best shrinkage coefficient for the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "alda_regression_lasso",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "def alda_regression_lasso(X_train, X_test, y_train, random_state=0):\n",
    "    # Perform lasso regression\n",
    "    # Inputs:\n",
    "    # X_train: training data frame(19 variables, x1-x19)\n",
    "    # X_test: test data frame(19 variables, x1-x19)\n",
    "    # y_train: dependent variable, training data (vector, continous type)\n",
    "    # random_state: a random state to use in CV model training\n",
    "    # General Information:\n",
    "        # use 10-fold cross validation to determine the best model hyperparameters\n",
    "    \n",
    "    # Output:\n",
    "    # A tuple containing:\n",
    "    # - The regression model and \n",
    "    # - The list of predictions on test data (X_test) (vector) \n",
    "  \n",
    "    # allowed packages: sklearn.linear_model\n",
    "  \n",
    "    # Function hints: Read the documentation for the functions LassoCV (link above)\n",
    "    \n",
    "    # write code for lasso regression here\n",
    "    # 10 fold cross validation\n",
    "    # set up the random_state as 0 in order for reproducibility\n",
    "    \n",
    "    data = LassoCV(cv=10, random_state=random_state).fit(X_train, y_train)\n",
    "    data_pred = data.predict(X_test)\n",
    "    \n",
    "    return (data, data_pred)\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before testing your model**: Do you expect the training error to be higher or lower? What about the testing error? What do you expect to be different about the coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE: 541.6957360523048\n",
      "Test RMSE: 639.4484997672894\n",
      "\n",
      "Model coefficients:\n",
      "[ -201.29823887   125.69640945   143.15397394   113.55339266\n",
      "     0.           452.14702148    78.0967967    -28.89070358\n",
      "    -0.            -8.62418868     0.           -92.58796998\n",
      "   -95.66296382 -2130.41737003  2429.16734481    -0.\n",
      "    -0.          -153.90630771   171.8676209 ]\n",
      "\n",
      "The shinkage coefficient hyperparameter chosen by CV: 3.196361962538218\n"
     ]
    }
   ],
   "source": [
    "lasso_model, lasso_predictions = alda_regression_lasso(X_train, X_test, y_train)\n",
    "\n",
    "# Should be ~541.7\n",
    "print(f'Training RMSE: {calculate_rmse(y_train, lasso_model.predict(X_train))}')\n",
    "# Should be ~639.4\n",
    "print(f'Test RMSE: {calculate_rmse(y_test, lasso_predictions)}')\n",
    "print('')\n",
    "\n",
    "# Which attributes are most predictive of the outcome variable?\n",
    "print(f'Model coefficients:\\n{lasso_model.coef_}')\n",
    "\n",
    "print()\n",
    "# Note we called this 'lamda' in class, but sklearn calls it alpha (should be ~3.196)\n",
    "print(f'The shinkage coefficient hyperparameter chosen by CV: {lasso_model.alpha_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "alda_regression_lasso-public",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "lasso_model, lasso_regression_result = alda_regression_lasso(X_train, X_test, y_train)\n",
    "np.testing.assert_equal(lasso_regression_result.shape, (27,))\n",
    "np.testing.assert_almost_equal(calculate_rmse(y_test, lasso_regression_result), 639.448499767289)\n",
    "np.testing.assert_almost_equal(lasso_model.coef_[0], -201.29823887)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "alda_regression_lasso-private",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Here's some more test cases\n",
    "df_test = pd.read_csv(\"./data/regression-test.csv\")\n",
    "X_test2 = df_test.iloc[:,:-1]\n",
    "y_test2 = df_test.iloc[:,-1]\n",
    "\n",
    "lasso_model, lasso_regression_result = alda_regression_lasso(X, X_test2, y)\n",
    "np.testing.assert_equal(lasso_regression_result.shape, (66,))\n",
    "np.testing.assert_almost_equal(calculate_rmse(y_test2, lasso_regression_result), 978.5702064182492)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-59f0827753c683dc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "From the results, compare the two regression models, including the training and testing RMSE, and the coefficients. Use the output of these functions to answer the following questions below:\n",
    "\n",
    "1. The dataset contains 19 attributes. Are all 19 attributes useful for predicting the dependent variable? Why or why not? Use your results to justify the answer.  The Use of lassoCV removed variables and set them to Zero because they were not essential in the classification of the data set.\n",
    "2. If not all attributes are predictive, use your Lasso model to perform feature selection. Which attributes should be kept? Use a correlation and/or scatter plot to justify your answer for at least one attribute (in a new cell below).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "comparison",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
