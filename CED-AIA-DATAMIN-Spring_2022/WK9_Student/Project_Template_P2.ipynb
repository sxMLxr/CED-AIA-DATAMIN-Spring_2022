{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Template: Phase 2\n",
    "\n",
    "Below are some concrete steps that you can take while doing your analysis for phase3. This guide isn't \"one size fit all\" so you will probably not do everything listed. But it still serves as a good \"pipeline\" for how to do data analysis.\n",
    "\n",
    "If you do engage in a step, you should clearly mention it in the notebook.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1) Decide on what models you will use and compare\n",
    "\n",
    "Select at least 3 models to compare on your prediction task. At least 2 of your models should be ones we've covered in class. \n",
    "\n",
    "Some resources try to help you select a well-performing model for your data:\n",
    "* [sklearn's Flowchart](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)\n",
    "* [geeks4geeks Flowchart](https://www.geeksforgeeks.org/flowchart-for-basic-machine-learning-models/)\n",
    "* [SAS Cheatsheet](https://blogs.sas.com/content/subconsciousmusings/files/2017/04/machine-learning-cheet-sheet.png)\n",
    "\n",
    "**Note**: These are general guides, and not guarantees of success. Some of the models are also outside of what we have covered, but you can explore them if you want to.\n",
    "\n",
    "In addition to selecting a model you think will perform well, there are other reasons to select a model:\n",
    "* To serve as a baseline (naive) approach you expect to outperform with more complex/appropriate models.\n",
    "* You need a model that is human interpretable (e.g. Decision Tree).\n",
    "* The model has historically performed well on similar tasks.\n",
    "* Some properties of the model are effective for the type of data you have. Remember, at the end of most Seminars, you learned the strengths and weaknesses of each model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Model XXX: I am selecting XXX because...\n",
    "2. Model YYY: I am selecting YYY because...\n",
    "3. Model ZZZ: I am selecting ZZZ because..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2) Split into train and test\n",
    "Make sure to split your data *before* you apply any transformations.\n",
    "\n",
    "**Note**: If you have multiple records from the same object (e.g., multiple attempts from the same student), these should all go in either training or test, but not split between them. See the examples for how to accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1) Sampling (If needed)\n",
    "\n",
    "If one of your classes is very underrepresented (e.g. 1000 of Class 0; 200 of Class 1), you might consider oversampling the minority class (e.g. sample 1000 times with replacement from 200 instances), or undersampling the majority class (e.g. sample 200 times from 1000 instances).\n",
    "\n",
    "Check out [np.random.choice](https://numpy.org/doc/stable/reference/random/generated/numpy.random.choice.html) for how to sample a vector.\n",
    "\n",
    "**Note 1**: You should only ever sample the *training dataset*, never the test. After all, you can't chose the class distribution of your test data!\n",
    "\n",
    "**Note 2**: Sampling can help a classifier perform better on the minority class, often at the cost of *overall* performance. But this is no guarantee. If you chose to sample, you should compare your classifiers' performance with and without sampling to see if it actually helped.\n",
    "\n",
    "**Note 3**: Make sure you sample the *same* indices from your training and test data -- otherwise they won't match anymore!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play around with sampling below (or skip this step if you don't need sampling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " When you're done, write the `sample_data` method to perform sampling on any training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(X_train, Y_train):\n",
    "    \"\"\"\n",
    "    Input: The original X_train and Y_train training dataset\n",
    "    Output: A new training dataset with sampling applied (same columns, different rows)\n",
    "    \"\"\"\n",
    "    # For example, undersample the majority class, or oversample the minority class.\n",
    "    \n",
    "    return (X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3) Feature Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your training data to fit any transformers or encoder your need, then apply the fit transformer to your test data. This applies to:\n",
    "* Normalizing/standardizing your features\n",
    "* Using Bag of Words or TF-IDF to encode strings\n",
    "* PCA or dimensionality reduction\n",
    "\n",
    "**Rationale**: In practice, we won't be able to see the test data we'll be making predicting for, so we shouldn't use that data as the basis for any transformation or feature extractio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try your feature transformation below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " When you're done, write the `apply_feature_transformation` method to perform transformation on any training/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_feature_transformation(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Input: The original X_train and X_test feature sets.\n",
    "    Output: The transformed X_train and X_test feature sets.\n",
    "    \"\"\"\n",
    "    return (X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4) Train and Explore your Models\n",
    "Using the models you decided upon in the beginning, now train these models. Conduct preliminary evaluations to see if using said models are even feasible, before potentially wasting time tuning a model thats no-good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5) Hyperparameter Tuning\n",
    "For promising models, tune them even further to squeeze out the best possible performance. Some questions to consider.\n",
    "\n",
    "1. What hyperparamaters should I tune? Why?\n",
    "2. What values ranges should I choose for each param? Why?\n",
    "3. Should I use try the values manually, or use the [built-in tuning functions](https://scikit-learn.org/stable/modules/grid_search.html)?\n",
    "\n",
    "**Make sure to only tune on the training dataset!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def find_best_hyperparameters_m1(X_train, Y_train):\n",
    "    \"\"\"\n",
    "    Input: The training X features and Y labels/values\n",
    "    Output: The classifier with the best hyperparams and the predictions\n",
    "    \"\"\"\n",
    "    clf = None # Create your base classifier\n",
    "    param_grid = {\"param_1\": [0, 1, 2],\n",
    "                  \"param_2\": ['value1', 'value2']}\n",
    "    \n",
    "    search = GridSearchCV(clf, param_grid)\n",
    "    search.fit(X_train,y_train)\n",
    "    return search, search.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put it All Together\n",
    "\n",
    "Now, combine the \"scratch work\" that you did above into a tidy function that someone could use to replicate your work and process in a single step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model1(X_train, X_test, Y_train, Y_test):\n",
    "    (X_train, X_test) = apply_feature_transformation(X_train, X_test)\n",
    "    (X_train, Y_train) = sample_data(X_train, Y_train)\n",
    "    hyperparameters = find_best_hyperparameters_m1(X_train, Y_train)\n",
    "    # Fit your model here\n",
    "    \n",
    "    # Return your model's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model2(X_train, X_test, Y_train, Y_test):\n",
    "    (X_train, X_test) = apply_feature_transformation(X_train, X_test)\n",
    "    (X_train, Y_train) = sample_data(X_train, Y_train)\n",
    "    # You need to create a new hyperparameter selector for your second model, or remove this step\n",
    "    hyperparameters = find_best_hyperparameters_m2(X_train, Y_train)\n",
    "    # Fit your model here\n",
    "    \n",
    "    # Return your model's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model3(X_train, X_test, Y_train, Y_test):\n",
    "    (X_train, X_test) = apply_feature_transformation(X_train, X_test)\n",
    "    (X_train, Y_train) = sample_data(X_train, Y_train)\n",
    "    # You need to create a new hyperparameter selector for your second model, or remove this step\n",
    "    hyperparameters = find_best_hyperparameters_m3(X_train, Y_train)\n",
    "    # Fit your model here\n",
    "    \n",
    "    # Return your model's predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
